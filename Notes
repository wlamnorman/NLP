Note-taking while reading. (Add this as bookmark: https://colah.github.io/)

To read:
https://machinelearningmastery.com/how-to-develop-a-word-level-neural-language-model-in-keras/ <- Try to implement similar model to begin with?
Book on the subject by the same author: https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwj19uCH1vP6AhU3QvEDHQnbA8sQFnoECBkQAQ&url=https%3A%2F%2Foku.ozturkibrahim.com%2Fdocs_python%2FDeep_Learning_for_Natural_Language_Processing.pdf&usg=AOvVaw3kN7Wl-cmLg5sHMNXKzz_X

N-grams:
Unigram - [Let] [me] [explain] [with] [an] [example.]
Bigram [let me] [me explain] [explain with] [with an] [an example]
Trigram [let me explain] [me explain with] [explain with an] [with an example]

Picking N small -> possibly very incoherent, N large -> overfitting
